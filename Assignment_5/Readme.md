
## Transformer

New deep learning models are introduced at an increasing rate and sometimes itâ€™s hard to keep track of all the novelties. That said, one particular neural network model has proven to be especially effective for common natural language processing tasks. The model is called a Transformer and it makes use of several methods and mechanisms

- Setting up the development environment, with the Pytorch-Transformers library by HuggingFace.
- Setting up pre-trained models.
- Implement multi head self attention as a Keras layer
- Implement a Transformer block as a layer
- Implement embedding layer: Two seperate embedding layers, one for tokens, one for token index (positions).
- Download and prepare dataset.
- Converting data into features.
- Create classifier model using transformer layer
- Fine-tuning models.
- Training and Evaluation.

## Accuracy

Achieved an accuracy of 92% after 2 epochs and validation accuracy of 87%
