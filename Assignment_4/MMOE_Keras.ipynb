{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MMOE_Keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWHZsb0S0qhddK+f3byZvX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranjani94/Advanced_Deep_Learning/blob/master/Assignment_4/MMOE_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo7DEegq3vl9",
        "outputId": "b91247bc-b24c-406b-e51f-d0159dd81d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUI38Qna3n95",
        "outputId": "46663b4d-1b50-4679-a1ed-501d6487e861",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "\"\"\"\n",
        "Multi-gate Mixture-of-Experts demo with census income data.\n",
        "Copyright (c) 2018 Drawbridge, Inc\n",
        "Licensed under the MIT License (see LICENSE for details)\n",
        "Written by Alvin Deng\n",
        "\"\"\"\n",
        "\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.initializers import VarianceScaling\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "SEED = 1\n",
        "\n",
        "# Fix numpy seed for reproducibility\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Fix random seed for reproducibility\n",
        "random.seed(SEED)\n",
        "\n",
        "# Fix TensorFlow graph-level seed for reproducibility\n",
        "tf.set_random_seed(SEED)\n",
        "tf_session = tf.Session(graph=tf.get_default_graph())\n",
        "K.set_session(tf_session)\n",
        "\n",
        "\n",
        "# Simple callback to print out ROC-AUC\n",
        "class ROCCallback(Callback):\n",
        "    def __init__(self, training_data, validation_data, test_data):\n",
        "        self.train_X = training_data[0]\n",
        "        self.train_Y = training_data[1]\n",
        "        self.validation_X = validation_data[0]\n",
        "        self.validation_Y = validation_data[1]\n",
        "        self.test_X = test_data[0]\n",
        "        self.test_Y = test_data[1]\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        train_prediction = self.model.predict(self.train_X)\n",
        "        validation_prediction = self.model.predict(self.validation_X)\n",
        "        test_prediction = self.model.predict(self.test_X)\n",
        "\n",
        "        # Iterate through each task and output their ROC-AUC across different datasets\n",
        "        for index, output_name in enumerate(self.model.output_names):\n",
        "            train_roc_auc = roc_auc_score(self.train_Y[index], train_prediction[index])\n",
        "            validation_roc_auc = roc_auc_score(self.validation_Y[index], validation_prediction[index])\n",
        "            test_roc_auc = roc_auc_score(self.test_Y[index], test_prediction[index])\n",
        "            print(\n",
        "                'ROC-AUC-{}-Train: {} ROC-AUC-{}-Validation: {} ROC-AUC-{}-Test: {}'.format(\n",
        "                    output_name, round(train_roc_auc, 4),\n",
        "                    output_name, round(validation_roc_auc, 4),\n",
        "                    output_name, round(test_roc_auc, 4)\n",
        "                )\n",
        "            )\n",
        "\n",
        "        return\n",
        "\n",
        "    def on_batch_begin(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        return\n",
        "\n",
        "\n",
        "def data_preparation():\n",
        "    # The column names are from\n",
        "    # https://www2.1010data.com/documentationcenter/prod/Tutorials/MachineLearningExamples/CensusIncomeDataSet.html\n",
        "    column_names = ['age', 'class_worker', 'det_ind_code', 'det_occ_code', 'education', 'wage_per_hour', 'hs_college',\n",
        "                    'marital_stat', 'major_ind_code', 'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member',\n",
        "                    'unemp_reason', 'full_or_part_emp', 'capital_gains', 'capital_losses', 'stock_dividends',\n",
        "                    'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat', 'det_hh_summ',\n",
        "                    'instance_weight', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
        "                    'num_emp', 'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
        "                    'own_or_self', 'vet_question', 'vet_benefits', 'weeks_worked', 'year', 'income_50k']\n",
        "\n",
        "    # Load the dataset in Pandas\n",
        "    train_df = pd.read_csv(\n",
        "        '/content/gdrive/My Drive/advanced_DL/datasets/data/census-income.data.gz',\n",
        "        delimiter=',',\n",
        "        header=None,\n",
        "        index_col=None,\n",
        "        names=column_names\n",
        "    )\n",
        "    other_df = pd.read_csv(\n",
        "        '/content/gdrive/My Drive/advanced_DL/datasets/data/census-income.test.gz',\n",
        "        delimiter=',',\n",
        "        header=None,\n",
        "        index_col=None,\n",
        "        names=column_names\n",
        "    )\n",
        "\n",
        "    # First group of tasks according to the paper\n",
        "    label_columns = ['income_50k', 'marital_stat']\n",
        "\n",
        "    # One-hot encoding categorical columns\n",
        "    categorical_columns = ['class_worker', 'det_ind_code', 'det_occ_code', 'education', 'hs_college', 'major_ind_code',\n",
        "                           'major_occ_code', 'race', 'hisp_origin', 'sex', 'union_member', 'unemp_reason',\n",
        "                           'full_or_part_emp', 'tax_filer_stat', 'region_prev_res', 'state_prev_res', 'det_hh_fam_stat',\n",
        "                           'det_hh_summ', 'mig_chg_msa', 'mig_chg_reg', 'mig_move_reg', 'mig_same', 'mig_prev_sunbelt',\n",
        "                           'fam_under_18', 'country_father', 'country_mother', 'country_self', 'citizenship',\n",
        "                           'vet_question']\n",
        "    train_raw_labels = train_df[label_columns]\n",
        "    other_raw_labels = other_df[label_columns]\n",
        "    transformed_train = pd.get_dummies(train_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
        "    transformed_other = pd.get_dummies(other_df.drop(label_columns, axis=1), columns=categorical_columns)\n",
        "\n",
        "    # Filling the missing column in the other set\n",
        "    transformed_other['det_hh_fam_stat_ Grandchild <18 ever marr not in subfamily'] = 0\n",
        "\n",
        "    # One-hot encoding categorical labels\n",
        "    train_income = to_categorical((train_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
        "    train_marital = to_categorical((train_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
        "    other_income = to_categorical((other_raw_labels.income_50k == ' 50000+.').astype(int), num_classes=2)\n",
        "    other_marital = to_categorical((other_raw_labels.marital_stat == ' Never married').astype(int), num_classes=2)\n",
        "\n",
        "    dict_outputs = {\n",
        "        'income': train_income.shape[1],\n",
        "        'marital': train_marital.shape[1]\n",
        "    }\n",
        "    dict_train_labels = {\n",
        "        'income': train_income,\n",
        "        'marital': train_marital\n",
        "    }\n",
        "    dict_other_labels = {\n",
        "        'income': other_income,\n",
        "        'marital': other_marital\n",
        "    }\n",
        "    output_info = [(dict_outputs[key], key) for key in sorted(dict_outputs.keys())]\n",
        "\n",
        "    # Split the other dataset into 1:1 validation to test according to the paper\n",
        "    validation_indices = transformed_other.sample(frac=0.5, replace=False, random_state=SEED).index\n",
        "    test_indices = list(set(transformed_other.index) - set(validation_indices))\n",
        "    validation_data = transformed_other.iloc[validation_indices]\n",
        "    validation_label = [dict_other_labels[key][validation_indices] for key in sorted(dict_other_labels.keys())]\n",
        "    test_data = transformed_other.iloc[test_indices]\n",
        "    test_label = [dict_other_labels[key][test_indices] for key in sorted(dict_other_labels.keys())]\n",
        "    train_data = transformed_train\n",
        "    train_label = [dict_train_labels[key] for key in sorted(dict_train_labels.keys())]\n",
        "\n",
        "    return train_data, train_label, validation_data, validation_label, test_data, test_label, output_info\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Load the data\n",
        "    train_data, train_label, validation_data, validation_label, test_data, test_label, output_info = data_preparation()\n",
        "    num_features = train_data.shape[1]\n",
        "\n",
        "    print('Training data shape = {}'.format(train_data.shape))\n",
        "    print('Validation data shape = {}'.format(validation_data.shape))\n",
        "    print('Test data shape = {}'.format(test_data.shape))\n",
        "\n",
        "    # Set up the input layer\n",
        "    input_layer = Input(shape=(num_features,))\n",
        "\n",
        "    # Set up MMoE layer\n",
        "    mmoe_layers = MMoE(\n",
        "        units=4,\n",
        "        num_experts=8,\n",
        "        num_tasks=2\n",
        "    )(input_layer)\n",
        "\n",
        "    output_layers = []\n",
        "\n",
        "    # Build tower layer from MMoE layer\n",
        "    for index, task_layer in enumerate(mmoe_layers):\n",
        "        tower_layer = Dense(\n",
        "            units=8,\n",
        "            activation='relu',\n",
        "            kernel_initializer=VarianceScaling())(task_layer)\n",
        "        output_layer = Dense(\n",
        "            units=output_info[index][0],\n",
        "            name=output_info[index][1],\n",
        "            activation='softmax',\n",
        "            kernel_initializer=VarianceScaling())(tower_layer)\n",
        "        output_layers.append(output_layer)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=[input_layer], outputs=output_layers)\n",
        "    adam_optimizer = Adam()\n",
        "    model.compile(\n",
        "        loss={'income': 'binary_crossentropy', 'marital': 'binary_crossentropy'},\n",
        "        optimizer=adam_optimizer,\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Print out model architecture summary\n",
        "    model.summary()\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x=train_data,\n",
        "        y=train_label,\n",
        "        validation_data=(validation_data, validation_label),\n",
        "        callbacks=[\n",
        "            ROCCallback(\n",
        "                training_data=(train_data, train_label),\n",
        "                validation_data=(validation_data, validation_label),\n",
        "                test_data=(test_data, test_label)\n",
        "            )\n",
        "        ],\n",
        "        epochs=100\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-659e200ee892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmoe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMMoE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mSEED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmoe'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzDxZfX24LU8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}