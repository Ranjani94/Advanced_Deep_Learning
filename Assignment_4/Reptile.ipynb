{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reptile.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZo03z6soP8L52HDKUcg48",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ranjani94/Advanced_Deep_Learning/blob/master/Assignment_4/Reptile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDGi22vzAZ5S"
      },
      "source": [
        "## Sine wave regression using reptile\n",
        "\n",
        "The goal of our algorithm is to learn to regress the value of y given the x. The value of amplitude is chosen randomly between 0.1 and 5.0 and the value of phase is chosen randomly between 0 and $\\pi$. So for each of the tasks, we sample only 10 data points and train the network. i.e for each of the tasks, we sample only 10 (x,y) pairs. let us get to the code and see in detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8lqtbW792_C"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRyY2LB-96-g"
      },
      "source": [
        "def sample_points(k):\n",
        "    \n",
        "    num_points = 100\n",
        "    \n",
        "    #amplitude\n",
        "    amplitude = np.random.uniform(low=0.1, high=5.0)\n",
        "    \n",
        "    #phase\n",
        "    phase = np.random.uniform(low=0, high=np.pi)\n",
        "\n",
        "    x = np.linspace(-5, 5, num_points)\n",
        "\n",
        "    #y = a*sin(x+b)\n",
        "    y = amplitude * np.sin(x + phase)\n",
        "    \n",
        "    #sample k data points\n",
        "    sample = np.random.choice(np.arange(num_points), size=k)\n",
        "    \n",
        "    return (x[sample], y[sample])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trCVj9xP99TB",
        "outputId": "04305118-795f-468d-c50d-4d0499a7bcdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x, y = sample_points(5)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.95959596 -0.25252525 -3.58585859  1.56565657  3.98989899]\n",
            "[ 0.64559314  3.95151586 -4.03001473 -1.73541673 -1.08340086]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQYoFgngAkU1"
      },
      "source": [
        "### Two layered neural network\n",
        "\n",
        "Like MAML, reptile also compatible with any algorithms that can be trained with gradient descent. So we use a simple two layered neural network with 64 hidden units."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg9fXDPp-2ab"
      },
      "source": [
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YHWQnh7-B-Z"
      },
      "source": [
        "# tf.reset_default_graph()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ln3Bl6P-EXo"
      },
      "source": [
        "num_hidden = 64\n",
        "num_classes = 1\n",
        "num_feature = 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lygHywW_-60X"
      },
      "source": [
        "X = tf.placeholder(tf.float32, shape=[None, num_feature])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, num_classes])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0wVWYuJ-9ln"
      },
      "source": [
        "w1 = tf.Variable(tf.random_uniform([num_feature, num_hidden]))\n",
        "b1 = tf.Variable(tf.random_uniform([num_hidden]))\n",
        "\n",
        "w2 = tf.Variable(tf.random_uniform([num_hidden, num_classes]))\n",
        "b2 = tf.Variable(tf.random_uniform([num_classes]))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H-uC6KR_61o"
      },
      "source": [
        "#layer 1\n",
        "z1 = tf.matmul(X, w1) + b1\n",
        "a1 = tf.nn.tanh(z1)\n",
        "\n",
        "#output layer\n",
        "z2 = tf.matmul(a1, w2) + b2\n",
        "Yhat = tf.nn.tanh(z2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehW9AduW_8ib"
      },
      "source": [
        "loss_function = tf.reduce_mean(tf.square(Yhat - Y))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah_6nBjz__oO"
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(1e-2).minimize(loss_function)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8fRI6tSABVg"
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8R9-Pg7AFht"
      },
      "source": [
        "### Reptile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beAINkzGADEJ"
      },
      "source": [
        "#number of epochs i.e training iterations\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "#number of samples i.e number of shots\n",
        "num_samples = 50  \n",
        "\n",
        "#number of tasks\n",
        "num_tasks = 2\n",
        "\n",
        "#number of times we want to perform optimization\n",
        "num_iterations = 10\n",
        "\n",
        "\n",
        "#mini btach size\n",
        "mini_batch = 10"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SMRbbHvAFBl",
        "outputId": "39df6709-e1ce-41fb-f6ff-17a2e1ee5bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#start the tensorflow session\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for e in range(num_epochs):\n",
        "        \n",
        "        #for each task in batch of tasks\n",
        "        for task in range(num_tasks):\n",
        "\n",
        "            #get the initial parameters of the model\n",
        "            old_w1, old_b1, old_w2, old_b2 = sess.run([w1, b1, w2, b2,])\n",
        "\n",
        "            #sample x and y\n",
        "            x_sample, y_sample = sample_points(num_samples)\n",
        "\n",
        "\n",
        "            #for some k number of iterations perform optimization on the task\n",
        "            for k in range(num_iterations):\n",
        "\n",
        "                #get the minibatch x and y\n",
        "                for i in range(0, num_samples, mini_batch):\n",
        "\n",
        "                    #sample mini batch of examples \n",
        "                    x_minibatch = x_sample[i:i+mini_batch]\n",
        "                    y_minibatch = y_sample[i:i+mini_batch]\n",
        "\n",
        "\n",
        "                    train = sess.run(optimizer, feed_dict={X: x_minibatch.reshape(mini_batch,1), \n",
        "                                                           Y: y_minibatch.reshape(mini_batch,1)})\n",
        "\n",
        "            #get the updated model parameters after several iterations of optimization\n",
        "            new_w1, new_b1, new_w2, new_b2 = sess.run([w1, b1, w2, b2])\n",
        "\n",
        "            #Now we perform meta update\n",
        "\n",
        "            #i.e theta = theta + epsilon * (theta_star - theta)\n",
        "\n",
        "            epsilon = 0.1\n",
        "\n",
        "            updated_w1 = old_w1 + epsilon * (new_w1 - old_w1) \n",
        "            updated_b1 = old_b1 + epsilon * (new_b1 - old_b1) \n",
        "\n",
        "            updated_w2 = old_w2 + epsilon * (new_w2 - old_w2) \n",
        "            updated_b2 = old_b2 + epsilon * (new_b2 - old_b2) \n",
        "\n",
        "\n",
        "            #update the model parameter with new parameters\n",
        "            w1.load(updated_w1, sess)\n",
        "            b1.load(updated_b1, sess)\n",
        "\n",
        "            w2.load(updated_w2, sess)\n",
        "            b2.load(updated_b2, sess)\n",
        "\n",
        "        if e%10 == 0:\n",
        "            loss = sess.run(loss_function, feed_dict={X: x_sample.reshape(num_samples,1), Y: y_sample.reshape(num_samples,1)})\n",
        "\n",
        "            print(\"Epoch {}: Loss {}\\n\".format(e,loss))\n",
        "            print('Updated Model Parameter Theta\\n')\n",
        "            print('Sampling Next Batch of Tasks \\n')\n",
        "            print('---------------------------------\\n')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 1.7375366687774658\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 10: Loss 7.7497639656066895\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 20: Loss 3.5970847606658936\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 30: Loss 2.590873956680298\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 40: Loss 1.6606582403182983\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 50: Loss 1.640143632888794\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 60: Loss 1.1941721439361572\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 70: Loss 4.566242218017578\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 80: Loss 12.019705772399902\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 90: Loss 10.947771072387695\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X8lBdRQAS0y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}